# File: docs/codex_directive_device_consistency_20250620.txt
# Purpose: Eliminate gradient device mismatch by guaranteeing all params + optimizer state on target device
# Audience: Codex backend agent
# Author: ChatGPT (o3)
# Date: 2025-06-20

#####################################################################
## 0. PROBLEM
#####################################################################
Training aborts with `RuntimeError: Gradient tensors on multiple devices`.
Some parameters stay on CPU after checkpoint restore.

#####################################################################
## 1. REQUIRED FIX (MANDATORY)
#####################################################################
1. **Re-apply `model.to(device)` _after_ loading the checkpoint.**
2. **Migrate optimizer tensors** to the same device.
3. Implement `ensure_model_device()` to detect and move any stray parameters.
4. Replace fatal gradient-device assert with automatic migration + warning.

#####################################################################
## 2. CODE CHANGES
#####################################################################
### 2.1 src/training_utils.py
```python
import torch, logging
log = logging.getLogger(__name__)

def migrate_optimizer_state(optim: torch.optim.Optimizer, device: torch.device):
    for state in optim.state.values():
        for k, v in state.items():
            if torch.is_tensor(v):
                state[k] = v.to(device, non_blocking=True)

def ensure_model_device(model: torch.nn.Module, device: torch.device):
    off = [n for n, p in model.named_parameters() if p.device != device]
    if off:
        log.warning("Migrating %d parameters to %s", len(off), device)
        model.to(device, non_blocking=True)
```

### 2.2 src/training.py (excerpt)
```python
model.load_state_dict(ckpt["model_state"])
optimizer.load_state_dict(ckpt["optim_state"])
scheduler.load_state_dict(ckpt["scheduler_state"])

# >>> ensure unified device <<<
model.to(device, non_blocking=True)
migrate_optimizer_state(optimizer, device)
ensure_model_device(model, device)
```

### 2.3 Remove hard assert
Delete the `RuntimeError` raise; instead call `ensure_model_device(model, device)` at epoch start.

#####################################################################
## 3. UNIT TEST
#####################################################################
`tests/test_device_consistency.py`
```python
from src.training_utils import migrate_optimizer_state, ensure_model_device
import torch

def test_migrate():
    model = torch.nn.Linear(2,2)
    opt = torch.optim.Adam(model.parameters())
    target = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(target)
    migrate_optimizer_state(opt, target)
    ensure_model_device(model, target)
    for state in opt.state.values():
        for v in state.values():
            if torch.is_tensor(v):
                assert v.device == target
```

`pytest -q` must pass on CPU-only.

#####################################################################
## 4. COMMIT MESSAGE
#####################################################################
`fix(train): auto-migrate stray CPU params & optimizer state`

#####################################################################
## 5. DEADLINE
#####################################################################
**1 hour** from receipt.

-- End of directive --
